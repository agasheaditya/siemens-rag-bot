{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bade20f-93f6-415e-b5f1-5eb0b5a8a51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import TextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e04f33b-2ad3-4030-a98f-b9618d321a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\adity\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a16d77b8-4d9e-44cc-bc86-c72cae0f7927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c12s05.pdf', 'The Making of Iron & Steel.pdf']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"../data/\"\n",
    "file_names = os.listdir(data_path)\n",
    "file_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13693d9f-dc64-442e-9634-3c8850618c7c",
   "metadata": {},
   "source": [
    "## Step 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a240c00c-725f-45de-ae0f-5ee2cdeb3d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def semantic_chunking(text, similarity_threshold=0.75):\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    chunks, current_chunk = [], [sentences[0]]\n",
    "    \n",
    "    for i in range(1, len(sentences)):\n",
    "        similarity = util.cos_sim(\n",
    "            model.encode(current_chunk[-1], convert_to_tensor=True),\n",
    "            model.encode(sentences[i], convert_to_tensor=True)\n",
    "        ).item()\n",
    "        \n",
    "        if similarity < similarity_threshold:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            current_chunk = [sentences[i]]\n",
    "        else:\n",
    "            current_chunk.append(sentences[i])\n",
    "    \n",
    "    chunks.append(\" \".join(current_chunk))  # Add the final chunk\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abf269a4-06d9-437a-b796-51f1b0839341",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticTextSplitter(TextSplitter):\n",
    "    def __init__(self, similarity_threshold=0.75):\n",
    "        super().__init__()\n",
    "        self.similarity_threshold = similarity_threshold\n",
    "        self.model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    \n",
    "    def split_text(self, text):\n",
    "        return semantic_chunking(text, self.similarity_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39824175-1939-4dd1-a7f6-f7b4afb645e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1152\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "for file in file_names:\n",
    "    full_file_name = os.path.join(data_path, file)\n",
    "    loader = PyPDFLoader(full_file_name)\n",
    "    # Use the custom splitter\n",
    "    semantic_splitter = SemanticTextSplitter(similarity_threshold=0.75)\n",
    "    documents += loader.load_and_split(text_splitter=semantic_splitter)\n",
    "\n",
    "\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196eb070-1ce1-448b-b097-8b0a57929da4",
   "metadata": {},
   "source": [
    "## Step 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adca2ea3-79da-4bdb-a900-8815e0ccfbf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\AppData\\Local\\Temp\\ipykernel_17664\\3184004565.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n"
     ]
    }
   ],
   "source": [
    "# Initialize the embedding model\n",
    "embedding_model = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "# Generate embeddings for your documents\n",
    "embeddings = [embedding_model.embed_query(doc.page_content) for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d79b9518-a3af-4ac2-bcd0-37c64b16df90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Chroma DB instance and store embeddings\n",
    "chroma_db = Chroma.from_documents(documents, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b6011af-c6c1-4541-a91b-e7bad72fe1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.5.1.2 Iron Production -\n",
      "Iron is produced in blast furnaces by the reduction of iron bearing materials with a hot gas.\n",
      "\n",
      "\n",
      "The iron is also used for feed in blast furnaces and BOF's when economics allow.\n",
      "\n",
      "\n",
      "Production \n",
      "of iron in the blast furnace is a thermo chemical process, during which the metal is reduced from \n",
      "its oxides by a series of chemical reactions and carburised to reduce its melting temperature.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test retrieval\n",
    "query = \"which furnace is used to produce the iron\"\n",
    "results = chroma_db.similarity_search(query, k=3)  # Retrieve top 3 relevant chunks\n",
    "for result in results:\n",
    "    print(result.page_content.rstrip())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75946c8d-6d2e-472b-a780-796766c36219",
   "metadata": {},
   "source": [
    "## Step : 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3141ffa3-268f-404c-ac3c-04e0d680826d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0167f0048ce04a6eab486ea8439a50ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the disk and cpu.\n"
     ]
    }
   ],
   "source": [
    "# Load the model and tokenizer\n",
    "model_name = \"meta-llama/Llama-2-7b-chat-hf\"  # Replace with your chosen model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", torch_dtype=\"auto\")\n",
    "\n",
    "# Load model directly\n",
    "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91200dc6-ec8c-424d-b65a-cc49ac4b45e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a sample query\n",
    "def generate_response(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(inputs.input_ids, max_length=200, temperature=0.1)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response\n",
    "\n",
    "prompt =  \"which furnace is used to produce the iron\"\n",
    "response = generate_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95165f4c-9a03-4c70-bee1-f9b3e9aec16d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e1cd21-3bf7-444a-8704-677496377c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806e6193-ec3c-4cec-bf29-fc7859c530fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98d10de-5458-4c01-ade3-64f9edb977dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0167f0048ce04a6eab486ea8439a50ab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_ad49f444aa544d6bade1f6cdd824673e",
        "IPY_MODEL_5209002250d94de793b1745d8ddbfbea",
        "IPY_MODEL_e1e6c324115c49e08bd8d1286763204a"
       ],
       "layout": "IPY_MODEL_c94be1f336a644c5b0348462a2ab3103"
      }
     },
     "048c233ffcd8472fabf0c64c9431bf9a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5209002250d94de793b1745d8ddbfbea": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_889d7f50d5794bb8a5201264401ffc15",
       "max": 2,
       "style": "IPY_MODEL_f97e90c2c04c40c3a062786df537f349",
       "value": 2
      }
     },
     "889d7f50d5794bb8a5201264401ffc15": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8a7ac39d666749b3958b31614ef88cd5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ad49f444aa544d6bade1f6cdd824673e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_048c233ffcd8472fabf0c64c9431bf9a",
       "style": "IPY_MODEL_8a7ac39d666749b3958b31614ef88cd5",
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "c0075901efd64bc9ba67a937c08df6b3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c94be1f336a644c5b0348462a2ab3103": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e1e6c324115c49e08bd8d1286763204a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_f9063151710b44cbbd70326c74f948e2",
       "style": "IPY_MODEL_c0075901efd64bc9ba67a937c08df6b3",
       "value": " 2/2 [00:08&lt;00:00,  8.11s/it]"
      }
     },
     "f9063151710b44cbbd70326c74f948e2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f97e90c2c04c40c3a062786df537f349": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
